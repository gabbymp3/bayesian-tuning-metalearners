{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Test Notebook\n",
    "\n",
    "This notebook runs a simple test of the X-learner hyperparameter tuning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from src.dgp import SimulatedDataset, simulate_dataset\n",
    "from src.xlearner import XlearnerWrapper\n",
    "from src.tuning import grid_search, random_search\n",
    "from src.metrics_helpers import pehe\n",
    "from src.experiment import run_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Simulated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Generated:\n",
      "  Sample size: 1000\n",
      "  Number of features: 15\n",
      "  Confounding strength (alpha): 0.1\n",
      "  Treatment distribution: 43.10% treated\n",
      "  True average treatment effect: 0.527\n",
      "  True treatment effect std: 0.784\n"
     ]
    }
   ],
   "source": [
    "# Create a simulated dataset\n",
    "dgp = SimulatedDataset(N=1000, d=15, alpha=0.1, seed=42)\n",
    "\n",
    "print(\"Dataset Generated:\")\n",
    "print(f\"  Sample size: {dgp.N}\")\n",
    "print(f\"  Number of features: {dgp.d}\")\n",
    "print(f\"  Confounding strength (alpha): {dgp.alpha}\")\n",
    "print(f\"  Treatment distribution: {np.mean(dgp.W):.2%} treated\")\n",
    "print(f\"  True average treatment effect: {np.mean(dgp.tau):.3f}\")\n",
    "print(f\"  True treatment effect std: {np.std(dgp.tau):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit X-Learner with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X-Learner Results (Default Parameters):\n",
      "  Predicted average treatment effect: 0.535\n",
      "  Predicted treatment effect std: 0.701\n",
      "  PEHE (lower is better): 0.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create and fit X-learner wrapper\n",
    "wrapper = XlearnerWrapper(\n",
    "    models=RandomForestRegressor(n_estimators=50, random_state=0),\n",
    "    propensity_model=RandomForestClassifier(n_estimators=50, random_state=0),\n",
    ")\n",
    "\n",
    "wrapper.fit(dgp.X, dgp.Y, W=dgp.W)\n",
    "\n",
    "# Predict CATE\n",
    "tau_pred = wrapper.predict(dgp.X)\n",
    "\n",
    "# Calculate PEHE\n",
    "pehe_score = pehe(dgp.tau, tau_pred)\n",
    "\n",
    "print(\"\\nX-Learner Results (Default Parameters):\")\n",
    "print(f\"  Predicted average treatment effect: {np.mean(tau_pred):.3f}\")\n",
    "print(f\"  Predicted treatment effect std: {np.std(tau_pred):.3f}\")\n",
    "print(f\"  PEHE (lower is better): {pehe_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Grid Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Grid Search...\n",
      "\n",
      "Grid Search Results:\n",
      "  Best parameters: {'models__n_estimators': 80, 'models__max_depth': 8}\n",
      "  Best CV score (MSE): 1.344\n",
      "  PEHE with tuned model: 0.146\n",
      "  PEHE improvement: 0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    \"models__n_estimators\": [20, 50, 80],\n",
    "    \"models__max_depth\": [3, 5, 8],\n",
    "}\n",
    "\n",
    "# Create base estimator\n",
    "base_estimator = XlearnerWrapper(\n",
    "    models=RandomForestRegressor(random_state=0),\n",
    "    propensity_model=RandomForestClassifier(n_estimators=50, random_state=0),\n",
    ")\n",
    "\n",
    "# Run grid search\n",
    "print(\"\\nRunning Grid Search...\")\n",
    "best_estimator, best_params, best_score = grid_search(\n",
    "    estimator=base_estimator,\n",
    "    param_grid=param_grid,\n",
    "    X=dgp.X,\n",
    "    Y=dgp.Y,\n",
    "    W=dgp.W,\n",
    "    cv=2,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Evaluate tuned model\n",
    "tau_pred_tuned = best_estimator.predict(dgp.X)\n",
    "pehe_tuned = pehe(dgp.tau, tau_pred_tuned)\n",
    "\n",
    "print(\"\\nGrid Search Results:\")\n",
    "print(f\"  Best parameters: {best_params}\")\n",
    "print(f\"  Best CV score (MSE): {best_score:.3f}\")\n",
    "print(f\"  PEHE with tuned model: {pehe_tuned:.3f}\")\n",
    "print(f\"  PEHE improvement: {pehe_score - pehe_tuned:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Small Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Experiment (R=3 repetitions)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment Results:\n",
      "\n",
      "Learner: x_rf, Tuner: grid\n",
      "  PEHE Mean: 0.344\n",
      "  PEHE Variance: 0.030\n",
      "  PEHE Plug-in Mean: 0.097\n",
      "  PEHE Plug-in Variance: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriellamessenger/Desktop/thesis/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define learners and tuners\n",
    "learners = [\n",
    "    {\n",
    "        \"name\": \"x_rf\",\n",
    "        \"models\": RandomForestRegressor(random_state=0),\n",
    "        \"propensity_model\": RandomForestClassifier(n_estimators=50, random_state=0),\n",
    "        \n",
    "    }\n",
    "]\n",
    "\n",
    "tuners = [\n",
    "    {\n",
    "        \"name\": \"grid\",\n",
    "        \"fn\": grid_search,\n",
    "        \"param_space\": {\"models__n_estimators\": [20, 50, 80, 100]},\n",
    "        \"kwargs\": {\"cv\": 3, \"verbose\": False}\n",
    "    }\n",
    "]\n",
    "\n",
    "dgp_params = {\"N\": 100, \"d\": 10, \"alpha\": 0.5}\n",
    "\n",
    "# Run experiment\n",
    "print(\"\\nRunning Experiment (R=3 repetitions)...\")\n",
    "summary, raw = run_experiment(\n",
    "    learners=learners,\n",
    "    tuners=tuners,\n",
    "    R=3,\n",
    "    simulate_dataset_fn=simulate_dataset,\n",
    "    dgp_params=dgp_params,\n",
    "    base_seed=42,\n",
    "    cv_plug=3\n",
    ")\n",
    "\n",
    "print(\"\\nExperiment Results:\")\n",
    "for result in summary:\n",
    "    print(f\"\\nLearner: {result['learner']}, Tuner: {result['tuner']}\")\n",
    "    print(f\"  PEHE Mean: {result['pehe_mean']:.3f}\")\n",
    "    print(f\"  PEHE Variance: {result['pehe_var']:.3f}\")\n",
    "    print(f\"  PEHE Plug-in Mean: {result['pehe_plug_mean']:.3f}\")\n",
    "    print(f\"  PEHE Plug-in Variance: {result['pehe_plug_var']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
